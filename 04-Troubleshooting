Troubleshooting         The process of identifying, analyzing and solving problems.
Debugging               The process of identifying, analyzing and removing bugs in a system.

Reproduction Case       A clear description of how and when the problem appears; a way to verify if the problem is present or not
Root Cause              Understanding the root cause is essential for performing the long-term remediation
    Hypothesis          Whenever possible, we should check our hyothesis in a test environment, instead of our production envirenment 
                                that our users are working with. 
System Calls            Calls that the programs running on our computer make to the running kernel
Observer Effect         Oberving a phenomenon alters the phenomenon
Power cycling           releases resources stored in cache or memory, which gets rid of the problem

Bisecting               cut problem in half and test each half seperately
                        cut possiblities for crash in half and test first half
                                 if first half causes the failure, the fault is in this group; else it's in the second
                                 continue further
                        there is also a command "git bisect"!?
                        
Cache                   Stores data in a form that is faster to access than its original form
                        e.g. Web Proxy: stores documents, videos, pictures often downloaded from the Internet
                        e.g. DNS-Services: store IP adresses for urls
Memory Leak             Memory which is no longer needed is not getting released


Problem Solving Steps
1. Getting Information
2. Finding the root cause
3. Performing the necessary remediation

----------------------------------------------------------------------------------------------------------------------------
Tools

ab                            # Apache Benchmark-Tool for benchmarking HTTP server
    ab -n 500 url             # get average timing of 500 requests
gdb                           # debugger for python programs
    gdb -c core               # debug a core dump after a system crash 
kill                          # kills a process
    kill -CONT                # continue stopped program, if program is still running, nothing will happen
    kill -STOP                # stops a program which can be continued or terminated
killall -STOP program_name    # stops program(s) with program_name, but does not kill them
strace                        # logs system calls, e.g. "strace ./run_program.py"
    strace -o file program    # store output to a file
iftop                         # shows network traffic
ionice                        # make our problem system reduce its priority
iostat                        # shows statistics on the input/output operations    
iotop                         # shows which processes use the most input and output
locate                        # find a given file
netstat                       # gives a bunch of information about our network connections depending on the passed flags. 
                              # This command accesses a bunch of sockets that are restricted to route the administrator user on Linux. 
                              # So we'll need to call it with sudo which lets us run commands as root, and then we'll pass a bunch of flags to netstat. 
    netstat -n                # print numerical addresses instead of resolving host names. 
    netstat -l                # check out the sockets that are listening for connection
    netstat -p                # print the process ID and name to which each socket belongs. 
                              # eg. sudo netstat -nlp | grep 80    >  grep for Port 80 
nice                          # start process with a different priority
pdb3                          # python debugger
    pdb3 <program> <params>   # activate debugger on python script
pidof                         # receives a process name and returns all corresponding process ids
ps
    ps ax                     # show all running processes on computer
renice                        # change priority of a running process
                              #           the lower the process priority number the higher the priority; typcial numbers go from 0 - 19
                              #           by default, processes start with a priority of 0
        renice priority pid   # e.g. for pid in $(pidof ffmpeg); do renice 19 $pid; done      
        
time <program_name>           # When we call time it runs the command that we pass to it and prints how long it took to execute it.
                -> Real is the amount of actual time that it took to execute the command. This value is sometimes called wall-clock time 
                                because it's how much time a clock hanging on the wall would measure no matter what the computer's doing. 
                -> User is the time spent doing operations in the user space. 
                -> Sys is the time spent doing system level operations.
top                           # shows state of computer and processes using the most cpu
                              # Load Average: shows how long a processer is busy in a given minute with 1 meaning it was busy all the time
                              #               normally this number should not be greater than the number of processors
                              #               if it is higher than the computer is overloaded
ulimit -c unlimited           # tell OS to create core files
vmstat                        # shows statistics on the virtual memory operations


tcpdump                       # powerful command-line analyzer that captures or "sniffs" TCP/IP packets
wireshark                     # open source tool for profiling network traffic and analyzing TCP/IP packets


# Script to continue STOPPED processes, one by one
# Continue first process (pid) and wait 1 second; continue process again, wait, ... until first pid does not exist any longer; head one to second pid
for pid in $(pidof ffmpeg); do while kill -CONT $pid; do sleep 1; done; done

----------------------------------------------------------------------------------------------------------------------------
Getting Information

- What were you trying to do? 
- What steps did you follow? 
- What was the expected result? 
- What was the actual result?

Find out, why computer is slow?
1. WHEN is the computer slow?


- Consider simplest explanation first!

System Logs:
  - on Linux:       /var/log/syslog
                    .xsession-errors
  - on Mac OS       /Library/Logs
  - on Windows      Event Viewer
  
-----------------------------------------------------------------------------------------------------------------------------
Linear Search        search from top to bottom
Binary Search        list must be sorted (sorting takes no time), but honestly does not make any sense if just one element is searched
                     compare to the middle element
                     > search in the second half, especially compare the middle element of the second half
                     < search in the first half, especially compare the middle element of the first half


-----------------------------------------------------------------------------------------------------------------------------
Efficient Code

- we should always start by writing clear code that does what it should and only try to make it faster if we realize that it's not fast enough
- trying to optimize every second out of a script is probably not worth your time.
- If we want our code to finish faster, we need to make our computer do less work, by
            - storing data that was already calculated to avoid calculating it again 
            - using the right data structures for the problem and 
            - reorganizing the code so that the computer can stay busy while waiting for information from slow sources like disk or over the network
            
Profiler            is a tool that measures the resources that our code is using, giving us a better understanding of what's going
                    -> use gprof to analyze a C program but use the c-Profile module to analyze a Python program
                    
    pprofile        e.g. pprofile -f callgrind -o profile.out <program_name>
                     We use the -f flag to tell it to use the call grind file format and the -o flag to tell it to store the output 
                     in the profile dot out file. This generated a file that we can open with any tool that supports the call grand 
    kcachegrind      format. We're going to use kcachegrind to look at the contents, which is a graphical interface for looking into these files.
                
expensive actions   are those that take a long time to complete

Lists

    Lists are sequences of elements. We can add, remove, or modify the elements in them. We can iterate through the whole list to operate on each of 
    the elements. Different programming languages call them differently. 
    The structure is called ArrayList in Java, Vector in C++, Array in Ruby, and Slice in Go.

    fast 
        to add or remove elements at the end. 
    slow
        But adding or removing elements in the middle can be slow because all the elements that follow need to be repositioned. 
    fast
        It's fast to access the element in a specific position in the list, 
    slow
        but finding an element in an unknown position requires going through the whole list. This can be super slow if the list is long. 

Dictionary        
 
    Dictionary store key value pairs. We add data by associating a value to a key. Then, we retrieve a value by looking up a specific key. 
    They are called HashMap in Java, Unordered Map in C++, Hash in Ruby, and Map in Go. 
     
     fast
         super-fast for looking up keys. Once we have our data stored in a dictionary, we can find the value associated to a key in just one operation. 
         
==> If you need to access elements by position or will always iterate through all the elements, use a list to store them. 
==> If we need to look up the elements using a key, we'll use a dictionary.


Expansive Loops ------------------------
If you do an expensive operation inside a loop, you multiply the time it takes to do the expensive operation by the amount of times you repeat the loop

- Make sure that the list of elements that you're iterating through is only as long as you really need it to be
- break out of the loop once you found what you were looking for (using "break" in python)
- the right solution for one problem might not be right for a different problem


Parallelizing -------------------------

A very easy way to run operations in parallel is just to split them across different processes, calling your script many times each with a 
different input set, and just let the operating system handle the concurrency.

So when doing operations in parallel, we need to find the right balance of simultaneous actions that let our computers stay busy without 
starving our system for resources!

Threads             let us run parallel tasks inside a process.  This allows threats to share some of the memory with other threads in the 
                    same process. Since this isn't handled by the OS, we'll need to modify our code to create and handle the threats. 

                    in python use Threading or Asyncio module
                    
IO bound            script is mostly just waiting on input or output
CPU bound           means the program is bottlenecked by the CPU (Central Processing Unit). When your program is waiting for I/O (e.g., 
                    disk read/write, network read/write), the CPU is free to do other tasks, even if your program is stopped. The speed of 
                    your program will mostly depend on how fast that I/O can happen; if you want to speed it up, you'll need to speed up the I/O. 
                    If your program is running lots of program instructions and not waiting for I/O, then it's CPU bound. Speeding up the CPU 
                    will make the program run faster.
                    In either case, the key to speeding up the program might not be to speed up the hardware but to optimize the program to 
                    reduce the amount of I/O or CPU it needs. Or you can have it do I/O while it also does CPU-intensive work. CPU bound implies 
                    that upgrading the CPU or optimizing code will improve the overall computing performance.  
                    
                    Example:
                    So, you check the CPU usage, and it looks like the script only uses a single core to run. But your server has a bunch of cores, 
                    which means the task is CPU-bound.


Slow database structure
    - if not available use one or more indexes (but not too mays)
    - establish a cache
    - distributing data to different servers
    - improve code for running on distributed systems
    - just to what you need to do

Using Threads to make things go faster:

Executor            This is the process that's in charge of distributing the work among the different workers
Futures Module      provides a couple of different executors, one for using threads and another for using processes

from concurrent import futures

def main():
    executor = futures.ThreadPoolExecutor()
    # Thread or Process? Threads contain certain security checks which make them slower
    # This is because, by using processes, we're making even more use of the CPU. The difference is caused by the way 
    # threads and processes work in Python. Threads use a bunch of safety features to avoid having two threads that try 
    # to write to the same variable. And this means that when using threads, they may end up waiting for their turn to 
    # write to variables for a few milliseconds, adding up to the small difference between the two approaches.
    executor = futures.ProceePoolExecutor()
    ...
    for loop:
        executor.submit(function_name, param1, param2)
    ....
    executor.shutdown()          # Program will continue while Threads are running; executor.shutdown() waits until all threads are done


psutil (process and system utilities) 
is a cross-platform library for retrieving information on running processes and system utilization (CPU, memory, disks, network, sensors) 
in Python. It's mainly useful for system monitoring, profiling, and limiting process resources and management of running processes.

psutil.cpu_percent()        shows CPU utilization
psutil.disk_io_counters()   shows the amount of byte read and byte write for disk I/O
psutil.net_io_counters()    shows byte received and byte sent for the network I/O bandwidth


Basics rsync command
rsync(remote sync) is a utility for efficiently transferring and synchronizing files between a computer and an external hard drive 
and across networked computers by comparing the modification time and size of files. One of the important features of rsync is that 
it works on the delta transfer algorithm, which means it'll only sync or copy the changes from the source to the destination instead 
of copying the whole file. This ultimately reduces the amount of data sent over the network.

The basic syntax of the rsync command is:       rsync [Options] [Source-Files-Dir] [Destination]

Some of the commonly used options in rsync command are listed below:

Options Uses
-v      Verbose output
-q      Suppress message output
-a      Archive files and directory while synchronizing
-r      Sync files and directories recursively
-b      Take the backup during synchronization
-z      Compress file data during the transfer

Example:

Copy or sync files locally:                         rsync -zvh [Source-Files-Dir] [Destination]
Copy or sync directory locally:                     rsync -zavh [Source-Files-Dir] [Destination]
Copy files and directories recursively locally:     rsync -zrvh [Source-Files-Dir] [Destination]

----------------------------------------------------------------------------------------------------
Crashing Programs

Search for Cause:
    - Review Application Logs
    - Do same action on different computer (include / exclude Installation / Configuration on same computer)
    - Does this happen reliably?
    - memtest86 - check health of RAM, run instead of boot to let it access all RAM
    - check for any changes since last stable application operation
    
If an application, activate "Degub Logging" (config / parameter) to receive extra logging inforation
or
trace system calls the program is making
    strace (Linux)
    dtruss (MacOO)
    Process Monitor (Windows)

To find the root cause of a crashing application we'll want to look at all available logs, figure out what changed, 
trace the system or library calls the program makes, and create the smallest possible reproduction case.

Wrapper     is a function or program that provides a compatibility layer between two functions or programs so they can work well together

System is crashed, how to investigate:
    - check logs (/var/logs)
    - Problem is on Webserver that runs on Port 80 (default port)
    - use netstat (s.a.) to find out which software runs on that port, e.g. nginx
    - look for configuration files (/etc/<application_name>), e.g. /etc/nginx

---------------------------------------------------------------------------------------------
Code that Crashes

Accessing invalid memory means that the process tried to access a portion of the system's memory that wasn't assigned to it

Undefined behavior          This means that the code is doing something that's not valid in the programming language. 
Valgrind / Dr. Memory       A very powerful tool that can tell us if the code is doing any invalid operations no matter if it crashes are not.
                                Valgrind  (Linux / Mac) or Dr. Memory (Linux / Windows)
Traceback                   shows the lines of the different functions that were being executed when the problem happened
Core files                  store all the information related to the crash so that we or someone else can debug what's going on, like a snapshot
                                taken when the program crashes; tell system to create core files / core dumps with "ulimit -c unlimited"
                                core file can be handed over to debugger with "gdb -c core"

Segmentation Faults (Segfaults):
    - forgetting to initialize a variable
    - trying to access a list element outside of the valid range
    - trying to use a portion of memory after having given it back
    - trying to write more data than the requested portion of memory can hold

Use a debugger or Debugging Symbols to identify Segfaults.
-> for python: use pdb interactive debugger
-> printf debugging: print messages / variables in program (comes from c - printf)
-> use Logging Module in Python:  The logging module sets debug messages to show up when the code fails. It can be used to notify users 
                                    when an error occurs, the reason why it occurred, and how to resolve it.
                                    
gdb
    - backtrace     --> show a summary of the function calls that were used to the point where the failure occurs
    - up            --> move to the calling function in the backtrace and check out the line and copy parameters that caused the crash
    - list          --> show lines around the current one
    - print <var>   --> print actual value of a variable
    
pdb3
    - start with pdb3 <program.py> <arguments>
    - gdb3 halts on first line, waits for input
    - "next" runs to next line of code
    - "continue" lets program runs until it fails












